---
layout: post
title: "Scaling Robot Supervision to Hundreds of Hours with RoboTurk: Robotic Manipulation Dataset through Human Reasoning and Dexterity"
short-summary: ""
summary: "We built a system that enables collecting large-scale robot manipulation datasets with human supervision and used it to collect the largest robot dataset ever collected via teleoperation."
feature-img: "assets/img/posts/2019-10-07-roboturk/mandlekar_iros19.png"
thumbnail: "assets/img/posts/2019-10-07-roboturk/mandlekar_iros19.png"
author: <a href="http://web.stanford.edu/~amandlek/">Ajay Mandlekar</a>, <a href="https://web.stanford.edu/~jaustinb/">Jonathan Booher</a>, <a href="https://www.maxspero.com/">Max Spero</a>, <a href="http://www.alberttung.com">Albert Tung</a>, <a href="https://www.linkedin.com/in/anchitgupta">Anchit Gupta</a>, <a href="http://ai.stanford.edu/~yukez/">Yuke Zhu</a>, <a href="https://www.cs.toronto.edu/~garg/">Animesh Garg</a>, <a href="http://cvgl.stanford.edu/silvio/">Silvio Savarese</a>, <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>
tags: [imitation learning, reinforcement learning, rl, ml, robotics]
---
Data-driven methods such as Reinforcement Learning and Self-Supervised Learning have demonstrated an impressive ability to collect large amounts of data autonomously and enable robotic skill learning from the data collected. However, when these methods are successful, they tend to converge to either one or a handful of related task solutions, preventing robots from generalizing to more varied scenarios.

{% figure %}
<video autoplay loop muted playsinline class="postimagehalf">
  <source src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/pick_bowl.mp4" type="video/mp4">
</video>
<video autoplay loop muted playsinline class="postimagehalf">
  <source src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/fail_pick_bowl.mp4" type="video/mp4">
</video>

<figcaption>
The robot has learned one solution that enables it to grasp the bowl when it is upright.
However, if the bowl is flipped over, it has no idea how to proceed. By contrast, humans are able to easily generalize to this new situation by realizing that they can simply push the bowl to the edge of the table to flip the bowl over and then grasp it. This capacity to easily identify another solution in a novel task instance is enabled by diverse prior experience.
</figcaption>
{% endfigure %}

For example, consider the above example where the robot has learned to grasp the bowl. The robot has learned one solution that enables it to grasp the bowl when it is upright.
However, if the bowl is flipped over, it has no idea how to proceed. By contrast, humans are able to easily generalize to this new situation by realizing that they can simply push the bowl to the edge of the table to flip the bowl over and then grasp it. This capacity to easily identify another solution in a novel task instance is enabled by diverse prior experience. 

What kind of data can help robots generalize?
-------------------------------------------------

To enable robots that truly generalize to new task instances, it is important to consider the ideal kinds of data that they should learn from. 

{% figure %}
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/drop.gif"/>
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/stuff.gif"/>
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/tip.gif"/>
<figcaption>
Ideally, a dataset contains diverse behaviors such as the ones shown above. These solutions might each be appropriate in different scenarios, and the robot should understand and learn from all of them to be able to generalize to new situations.
</figcaption>
{% endfigure %}

**Diversity**. The data should contain diverse behaviors that demonstrate different approaches to solving a task. In the above example, different strategies are used for placing the water bottle into the container. In one case, the robot is able to just directly drop the bottle into the container, but in the other cases, it needs to stuff to water bottle in, or tip it in. 

{% figure %}
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/search.gif"/>
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/replan_grasp.gif"/>
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/twist_to_grasp.gif"/>
<figcaption>
Ideally, a dataset contains instances of dexterous manipulation like the examples shown above. By learning from this data, the robot should understand how to perform fine-grained manipulation that is important for solving the task.
</figcaption>
{% endfigure %}

**Dexterity**. The data could contain instances of dexterous manipulation so that the robot can learn fine-grained manipulation behaviors. This is important for ensuring that the robot can actually understand how to act in different scenarios. The above example shows the robot searching through the bin, replanning a grasp, and moving the object into a good position in order to grasp it.

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/object_search_large_scale.png"/>
<figcaption>
Ideally, a dataset should be large-scale so that the robot can learn from several diverse settings.
</figcaption>
{% endfigure %}

**Large-Scale**. Finally, there should be a large amount of data, so that the robot has learned from countless diverse situations and solutions. 

Collecting data to help robots generalize
-------------------------------------------------

There are several methods that have been used to collect robotic data in the past. Here, we evaluate the ability of each method to collect desirable data for generalization.

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/comparison_table.png"/>
<figcaption>
Comparison of prior data collection methodologies and RoboTurk.
</figcaption>
{% endfigure %}

Many data collection mechanisms and algorithms such as Self-Supervised Learning[^SSL] and Deep Reinforcement Learning[^qtopt] use **random exploration** to collect their data. While this allows the robot to autonomously collect data that is both dexterous and large-scale, the data is strongly correlated and _lacks diversity_. This is because data is collected purely at random at first, and over time, methods converge to specific solution strategies.

By contrast, human supervision allows for direct specification of task solutions. Prior mechanisms[^roboflow] have allowed humans to leverage **graphical web interfaces** to guide robots through tasks. While such data collection schemes allow for diverse data to be collected at scale through humans, the interface _limits the dexterity_ of the robot motions that can be demonstrated. For example, in the video above, a user has specified a program for the robot to execute, and the robot takes care of picking up the cups using simple top-down grasps. The human does not have much of a say in _how_ the task is done.  

Others have developed **motion interfaces** to enable a direct one-to-one mapping between human motion and the end effector of the arm. One such example[^deep_imitation] is a person using a Virtual Reality headset and controller to guide the arm through a pick-and-place task. By offering users full control over how the arm accomplishes the task, this allows for data that is both diverse and dexterous. However, this _does not allow for large-scale_ data collection, since the special hardware needed to develop such interfaces is not widely available. 

Our goal was to develop a data collection mechanism that could simulataneously collect data that is diverse, dexterous, and that could be collected at scale. To address these challenges, we developed <a href="http://roboturk.stanford.edu/">RoboTurk</a>.

RoboTurk
---------

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/sys_fig.png"/>
<figcaption>
RoboTurk is a platform that allows remote users to teleoperate robots in real-time with only a smartphone and a web browser. The platform supports many simultaneous users, each controlling their own robot.
</figcaption>
{% endfigure %}

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/alps.gif"/>
<figcaption>
RoboTurk enables remote teleoperation and data collection from anywhere - even in the Alps!
</figcaption>
{% endfigure %}

<a href="http://roboturk.stanford.edu/">RoboTurk</a> is a platform that allows remote users to teleoperate robots in real-time with only a smartphone and a web browser. Our platform supports many simultaneous users, each controlling their own robot remotely. A new user can get started in less than 5 minutes - all they need to do is download our smartphone application and go to our website, and they are ready to start collecting data.

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/interface.gif"/>
<figcaption>
Users receive a video stream of the robot workspace in their web browser and use their phone to guide the robot through a task. The motion of the phone is coupled to the motion of the robot, allowing for natural and dexterous control of the arm.
</figcaption>
{% endfigure %}

Users receive a video stream of the robot workspace in their web browser and use their phone to guide the robot through a task. The motion of the phone is coupled to the motion of the robot, allowing for natural and dexterous control of the arm.

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/pilot_dataset_vid.gif"/>
<figcaption>
In prior work, we used RoboTurk to collect a large simulation pilot dataset consisting of over 2000 task demonstrations in just 22 hours of total system usage.
</figcaption>
{% endfigure %}

RoboTurk is able to collect data that exhibits properties for enabling robots to generalize.

- **Diversity**. RoboTurk can be used to collect _diverse_ data by leveraging many simultaneous users for data collection.

- **Dexterity**. RoboTurk offers full 6-DoF control of the robot arm through a natural phone interface, allowing for _dexterity_ in the data.

- **Large-Scale**. RoboTurk allows for _large-scale_ data collection - we collected a <a href="http://roboturk.stanford.edu/dataset.html">Pilot Dataset</a> consisting of over 2000 task demonstrations in just 22 hours of total system usage.

Data Collection and Tasks
---------

In previous work, we used RoboTurk to collect a large dataset using robot manipulation tasks developed using [MuJoCo](http://www.mujoco.org) and [robosuite](https://github.com/StanfordVL/robosuite). In this work, we extended RoboTurk to enable data collection with physical robot arms, and used it to collect [the largest teleoperated robot manipulation dataset](http://roboturk.stanford.edu/realrobotdataset). 

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/mandlekar_iros19.png"/>
<figcaption>
We collected data on three Sawyer robot arms - each of which had a front-facing webcam and a top-down Kinect depth camera mounted in the workspace of the robot arm.
</figcaption>
{% endfigure %}

We collected data on three Sawyer robot arms - each of which had a front-facing webcam and a top-down Kinect depth camera mounted in the workspace of the robot arm. We collected RGB images from the front-facing RGB camera (which is also the teleoperator video stream view) at 30Hz, RGB and Depth images from the top-down Kinectv2 sensor also at 30Hz, and robot sensor readings such as joint and end effector information, at approximately 100Hz.

We collected our dataset using 54 different participants over the course of 1 week. Every user participated in a supervised hour of remote data collection, including a brief 5 minute tutorial at the beginning of the session. Afterwards, they were given the option to collect data without supervision for all subsequent collection. The users who participated in our data collection study collected the data from a variety of locations. All locations were remote - no data collection occurred in front of the actual robot arms.

#### Tasks

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/tasks.png"/>
<figcaption>
We designed three robotic manipulation tasks for data collection - Object Search, Tower Creation, and Laundry Layout. 
</figcaption>
{% endfigure %}

We designed three robotic manipulation tasks for data collection, shown above. These tasks were chosen with care in order to make sure that the data collected would be useful for robot generalization. Each task admits _diverse_ solution strategies, which encouraged our diverse set of users to experiment with different solution strategies, requires _dexterous_ manipulation to solve, and the robot needs to learn to _generalize_ to several scenarios. We also note that the tasks would be incredibly difficult to simulate, making physical data collection necessary.

{% figure %}
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/object_search_task_1.gif"/>
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/object_search_task_2.gif"/>
<figcaption>
In the Object Search task, the goal is to search for target objects (left) and fit them into a specific box (right).
</figcaption>
{% endfigure %}

- **Object Search**. The goal of this task is to search for a set of target objects within a cluttered bin and fit them into a specific box. There are three target object categories: _plush animals_, _plastic water bottles_, and _paper napkins_. The workspace consists of a large cluttered bin containing a diverse assortment of objects and three target boxes, one per category of target object. At the start of each task instance, three target objects of each category are mixed in among the clutter of the box. A target category is randomly sampled and relayed to the operator, who must use the robot arm to find all three objects corresponding to the target category and place each item into its corresponding hole. The objects also have interesting properties - the paper napkins appear in crumpled and unfolded configurations, and the crushed plastic water bottles are challenging to detect and grasp due to their translucence and arbitrary rigid shape.

{% figure %}
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/tower_creation_task_1.gif"/>
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/tower_creation_task_2.gif"/>
<figcaption>
In the Tower Creation task, the goal is to stack cups and bowls (left) to build the tallest tower possible (right).
</figcaption>
{% endfigure %}

- **Tower Creation**. In this task, an assortment of cups and bowls are arranged on the table. The goal of the task is to create the tallest tower possible by stacking the cups and bowls on top of each other. This task requires physical reasoning over the properties of each type of cup and bowl and thinking about how to stack them on top of each other to maximize height without sacrificing the stability of the tower. We diversify the initial task configurations by sampling a set of ten objects drawn from a total of 28 bowls in 7 varieties and 12 cups in 3 varieties. We also randomize the initial configuration of the objects. This encourages diversity in the demonstrations since users will not receive the same set of objects in the same configuration, enforcing each demonstration to be unique.

{% figure %}
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/laundry_layout_task_1.gif"/>
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/laundry_layout_task_2.gif"/>
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/laundry_layout_task_3.gif"/>
<figcaption>
In the Laundry Layout task, the goal is to layout towels (left), jeans (middle), and t-shirts (right).
</figcaption>
{% endfigure %}

- **Laundry Layout**. This task starts with a hand towel, a pair of jeans, or a t-shirt placed on the table. The goal is to use the robot arm to straighten the item so that it lies flat on the table with no folds. On every task reset we randomly place the item into a new configuration.

#### What do we expect from human supervision?

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/human_supervision.png"/>
<figcaption>
</figcaption>
{% endfigure %}

The figure above shows some examples of how we expect humans to use cognitive and physical reasoning to solve the tasks and endow our dataset with diversity, dexterity, and examples of generalization.

#### Dataset Statistics

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dataset_video.gif"/>
<figcaption>
We collected data on three Sawyer robot arms - each of which had a front-facing webcam and a top-down Kinect depth camera mounted in the workspace of the robot arm.
</figcaption>
{% endfigure %}

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dataset_comparison.png"/>
<figcaption>
Our dataset is the largest robot manipulation dataset ever collected using teleoperation.
</figcaption>
{% endfigure %}

We collected over 111 hours of total robot manipulation data in just 1 week across 54 users on our 3 manipulation tasks, with over 2000 successful demonstrations in total. This makes our dataset 1-2 orders of magnitude larger than most other datasets in terms of interaction time. The number of task demonstrations in our dataset also compares favorably with the number of demonstrations in large datasets such as MIME[^MIME], but the tasks that we collected data on are more difficult to complete, as they take on the order of minutes to complete successfully, as opposed to seconds.


Platform Evaluation
---------

#### Diversity and Dexterity in the Data

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/diversity_transition.gif"/>
<figcaption>
Our users surprised us by building intricate structures out of the simple sets of cups and bowls.
</figcaption>
{% endfigure %}

{% figure %}
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/diversity_3.png"/>
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/diversity_4.png"/>
<figcaption>
Some notable emergent solution strategies that were observed include building an inverted cone (left) and alternating cups and bowls for stability (right).
</figcaption>
{% endfigure %}

{% figure %}
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/diversity_5.png"/>
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/diversity_6.png"/>
<figcaption>
Some notable emergent solution strategies that were observed include flipping over a bowl for the base of the tower (left) and grouping 3 cups together to form a stable platform (right).
</figcaption>
{% endfigure %}

On the _Tower Creation_ task, our users surprised us by building intricate structures out of the simple sets of cups and bowls. We also saw a great deal of diversity in the towers that people chose to build. Some notable emergent solution strategies that were observed include building an inverted cone and alternating cups and bowls for stability, as well as flipping over a bowl for the base of the tower and grouping 3 cups together to form a stable platform. In particular, we had no idea that it was even possible to flip a bowl over given the kinematics of the Sawyer arm and the phone interface - it truly speaks to the power of human creativity coupled with the dexterity that the interface enables. 

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/completion_per_user.png"/>
<figcaption>
Average task completion times per user, sorted from fastest to slowest. Users exhibit large variation in skill level.
</figcaption>
{% endfigure %}

The users themselves were diverse - their skill levels varied significantly. This can be seen from the large variation in average task completion time per user on the _Object Search_ and _Laundry Layout_ tasks in the plot above. Note that most users were determined to use all 5 of their allotted minutes for the _Tower Creation_ task.

Next, we present some qualitative examples of diverse and dexterous behaviors in the _Object Search_ task.

{% figure %}
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dext_1.gif"/>
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dext_2.gif"/>
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dext_3.gif"/>
<figcaption>
The operators carefully manipulated objects in order to grasp them successfully.
</figcaption>
{% endfigure %}

In the examples above, the operators used the arm to manipulate the plastic water bottle into a favorable place in order to grasp it successfully.

{% figure %}
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dext_4.gif"/>
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dext_5.gif"/>
<figcaption>
The operators extracted items from the clutter in order to successfully grasp them.
</figcaption>
{% endfigure %}

In the examples above, the operators decided to extract items from the clutter in order to successfully grasp them.

{% figure %}
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dext_6.gif"/>
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dext_7.gif"/>
<img class="postimagethird" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dext_8.gif"/>
<figcaption>
The operators used different strategies to fit items into the containers.
</figcaption>
{% endfigure %}

The examples above show three different strategies we observed for placing target objects into the correct container:

- **clever grasp** (left): by using a strategic grasp, the operator is able to simply drop the bottle into the container
- **stuff** (middle): the operator stuffs the napkin into the container
- **strategic object use** (right): the operator uses one object to poke the other object into the container.

{% figure %}
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dext_9.gif"/>
<img class="postimagehalf" src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/dext_10.gif"/>
<figcaption>
Operators were able to recover from unsuccessful grasps.
</figcaption>
{% endfigure %}

The examples above show instances where the operator was able to recover from an unsuccessful grasp. 


#### Scaling to New Users

All 54 of our users were new, non-expert users. We found that **users with no experience started generating useful data in a matter of minutes**. On _Object Search_, new users were able to successfully pick and place a target object for the first time in an average of X minutes, and able to accomplish the entire task in Y minutes. On _Laundry Layout_, new users were able to successfully layout their first towel in less than 4 minutes on average. 

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/experience_wide.png"/>
<figcaption>
We witnessed significant user improvement over time. Users learned to complete tasks more quickly over time. Users controlled the phone orientation more, allowing them to take advantage of full 6-DoF control to generate dexterous task solutions of increasing quality.
</figcaption>
{% endfigure %}

Furthermore, we witnessed **significant user improvement over time**. As shown above, users learned to complete the task more efficiently over time as they collected more demonstrations. Furthermore, users moved the orientation of the phone more with increasing experience, suggesting that they learned to leverage full 6-DoF control to generate dexterous task solutions of increasing quality.

Leveraging the Dataset
----------

We provide some examples applications for our dataset. However, we emphasize that our dataset can be useful for several other applications as well, such as multimodal density estimation, policy learning, and hierarchical task planning. 

#### Reward Learning

{% figure %}
<img src="{{ site.baseurl }}/assets/img/posts/2019-10-07-roboturk/reward_curve.png"/>
<figcaption>
We learned an embedding space over RGB images on the Laundry Layout task. We plot the negative L2 embedding distance between a target frame with a flat towel (the last frame) and all other frames in a demonstrations. This distance provides a meaningful reward function for imitation as well as a useful metric for task progress.
</figcaption>
{% endfigure %}

Consider the problem of learning a policy to imitate a specific video demonstration. Prior work has approached this problem by learning an embedding space over visual observations and then crafting a reward function to imitate a reference trajectory based on distances in the embedding space. This reward function can then be used with reinforcement learning to learn a policy that imitates the trajectory. Taking inspiration from this approach, we trained a modified version of Time Contrastive Networks (TCN)[^TCN] on Laundry Layout demonstrations and investigate some interesting properties of the embedding space. 

In the figure above, we consider the frame embeddings along a single _Laundry Layout_ demonstration. We plot the negative L2 distance of the frame embeddings with respect to the embedding of a target frame near the end of the video, where the target frame depicts a successful task completion with the towel lying flat on the table. The figure demonstrates that distances in this embedding space with a suitable target frame yield a reasonable reward function that could be used to imitate task demonstrations purely from visual observations. 

Furthermore, embedding distances capture task semantics to a certain degree and could even be used to measure task progress. For example, in frames 3 and 5, the towel is nearly flat on the table, and the embedding distance to frame 6 is correspondingly small. By contrast, in frames 2 and 4, the robot is holding the towel a significant distance away from the table, and the distance to frame 6 is correspondingly large.

#### Video Prediction

TODO: fill this section out...

#### Behavioral Cloning

We also trained policies using Behavioral Cloning on the _Laundry Layout_ task by learning a mapping from RGB images to robot end effector positions. Our attempts to learn from the entire dataset were ultimately unsuccessful due to the diverse nature of the demonstrations, but we were able to achieve some success by restricting the training data to demonstration segments where the arm moves to a corner of the towel, and lifts the towel up. Addressing the diversity of the dataset for policy learning is left for future work.

Summary
----------

- RoboTurk is the first robot data collection platform that allows for collecting robot manipulation data that has _diversity_, _dexterity_, and is _large-scale_, which are all critical properties to enable robots that can generalize to new situations.

- We introduced three challenging manipulation tasks: _Object Search_, _Tower Creation_, and _Laundry Layout_. These tasks admit diverse solutions and strategies and require dexterous manipulation to solve. Significant generalization capability is also required for robots to solve these tasks due to the large variation in task instance.

- We presented the [largest known crowdsourced teleoperated robot manipulation dataset](http://roboturk.stanford.edu/realrobotdataset) consisting of over 111 hours of data across 54 users. The dataset was collected in 1 week on 3 Sawyer robot arms using the RoboTurk platform. We made important extensions to the RoboTurk platform to enable data collection on physical robots, including accounting for additional delays in the remote teleoperation loop due to physical robot actuation, ensuring operational safety of the robots when being controlled by novices, and managing large-scale data collection across multiple sensor streams.

- We evaluated our platform and showed that it can scale easily to new users, that the data collected consists of diverse and dexterous task solutions, and that the dataset has several applications such as multimodal density estimation, video prediction, reward function learning, policy learning and hierarchical task planning.

<hr>

This blog post is based on the IROS 2019 paper "Scaling Robot Supervision to Hundreds of Hours with RoboTurk: Robotic Manipulation Dataset through Human Reasoning and Dexterity" by Ajay Mandlekar, Jonathan Booher, Max Spero, Albert Tung, Anchit Gupta, Yuke Zhu, Animesh Garg, Silvio Savarese, and Li Fei-Fei. 

[^SSL]: Levine, S., Pastor, P., Krizhevsky, A., & Quillen, D. (2016, October). Learning hand-eye coordination for robotic grasping with large-scale data collection. In International Symposium on Experimental Robotics (pp. 173-184). Springer, Cham.
[^qtopt]: Quillen, D., Jang, E., Nachum, O., Finn, C., Ibarz, J., & Levine, S. (2018, May). Deep reinforcement learning for vision-based robotic grasping: A simulated comparative evaluation of off-policy methods. In 2018 IEEE International Conference on Robotics and Automation (ICRA) (pp. 6284-6291). IEEE.
[^roboflow]: Alexandrova, S., Tatlock, Z., & Cakmak, M. (2015, May). RoboFlow: A flow-based visual programming language for mobile manipulation tasks. In 2015 IEEE International Conference on Robotics and Automation (ICRA) (pp. 5537-5544). IEEE.
[^deep_imitation]: Zhang, T., McCarthy, Z., Jow, O., Lee, D., Chen, X., Goldberg, K., & Abbeel, P. (2018, May). Deep imitation learning for complex manipulation tasks from virtual reality teleoperation. In 2018 IEEE International Conference on Robotics and Automation (ICRA) (pp. 1-8). IEEE.
[^MIME]: Sharma, P., Mohan, L., Pinto, L., & Gupta, A. (2018). Multiple interactions made easy (mime): Large scale demonstrations data for imitation. arXiv preprint arXiv:1810.07121.
[^TCN]: Sermanet, P., Lynch, C., Chebotar, Y., Hsu, J., Jang, E., Schaal, S., ... & Brain, G. (2018, May). Time-contrastive networks: Self-supervised learning from video. In 2018 IEEE International Conference on Robotics and Automation (ICRA) (pp. 1134-1141). IEEE.
  
